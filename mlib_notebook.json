{"paragraphs":[{"text":"//load an filter the yellow taxi data, transform the data type\nval taxiDF = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"model\", \"DROPMALFORMED\").load(\"/user/yw2504/finalProject/yellow/2015/*.csv\")\ntaxiDF.registerTempTable(\"trip\")\nval DF = spark.sql(\"select * from trip where VendorID not like '%end%'\")\nDF.registerTempTable(\"DF\")\nval df = sqlContext.sql(\"select pickup_latitude, pickup_longitude, dropoff_latitude, dropoff_longitude, tpep_pickup_datetime, tpep_dropoff_datetime from DF\")\nval pick_time = unix_timestamp($\"tpep_pickup_datetime\",\"yyyy-MM-dd HH:mm:ss\").cast(\"timestamp\")\nval dropoff_time = unix_timestamp($\"tpep_dropoff_datetime\",\"yyyy-MM-dd HH:mm:ss\").cast(\"timestamp\")\nimport org.apache.spark.sql.types.DoubleType\nval pos_time = df.\n        withColumn(\"pickup_time\", pick_time).drop(\"tpep_pickup_datetime\").\n        withColumn(\"dropoff_time\", dropoff_time).drop(\"tpep_dropoff_datetime\").\n        withColumn(\"pickup_latitudeTmp\", df(\"pickup_latitude\").cast(DoubleType)).drop(\"pickup_latitude\").withColumnRenamed(\"pickup_latitudeTmp\", \"pickup_latitude\").\n\t\twithColumn(\"pickup_longitudeTmp\", df(\"pickup_longitude\").cast(DoubleType)).drop(\"pickup_longitude\").withColumnRenamed(\"pickup_longitudeTmp\", \"pickup_longitude\").\n\t\twithColumn(\"dropoff_latitudeTmp\", df(\"dropoff_latitude\").cast(DoubleType)).drop(\"dropoff_latitude\").withColumnRenamed(\"dropoff_latitudeTmp\", \"dropoff_latitude\").\n\t\twithColumn(\"dropoff_longitudeTmp\", df(\"dropoff_longitude\").cast(DoubleType)).drop(\"dropoff_longitude\").withColumnRenamed(\"dropoff_longitudeTmp\", \"dropoff_longitude\")\nval tripData = pos_time.filter(pos_time(\"pickup_latitude\") < 40.915568 && pos_time(\"pickup_latitude\") > 40.495992).\n\t\tfilter(pos_time(\"pickup_longitude\") < -73.699215 && pos_time(\"pickup_longitude\") > -74.257159).\n\t\tfilter(pos_time(\"dropoff_latitude\") < 40.915568 && pos_time(\"dropoff_latitude\") > 40.495992).\n\t\tfilter(pos_time(\"dropoff_longitude\") < -73.699215 && pos_time(\"dropoff_longitude\") > -74.257159)\ntripData.printSchema\ntripData.createOrReplaceTempView(\"tripData\")","user":"anonymous","dateUpdated":"2017-04-30T08:51:19-0400","config":{"enabled":true,"editorMode":"ace/mode/scala","results":{},"editorSetting":{"language":"scala"},"colWidth":12,"tableHide":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\ntaxiDF: org.apache.spark.sql.DataFrame = [VendorID: string, tpep_pickup_datetime: string ... 17 more fields]\n\nwarning: there was one deprecation warning; re-run with -deprecation for details\n\nDF: org.apache.spark.sql.DataFrame = [VendorID: string, tpep_pickup_datetime: string ... 17 more fields]\n\nwarning: there was one deprecation warning; re-run with -deprecation for details\n\ndf: org.apache.spark.sql.DataFrame = [pickup_latitude: string, pickup_longitude: string ... 4 more fields]\n\npick_time: org.apache.spark.sql.Column = CAST(unix_timestamp(tpep_pickup_datetime, yyyy-MM-dd HH:mm:ss) AS TIMESTAMP)\n\ndropoff_time: org.apache.spark.sql.Column = CAST(unix_timestamp(tpep_dropoff_datetime, yyyy-MM-dd HH:mm:ss) AS TIMESTAMP)\n\nimport org.apache.spark.sql.types.DoubleType\n\npos_time: org.apache.spark.sql.DataFrame = [pickup_time: timestamp, dropoff_time: timestamp ... 4 more fields]\n\ntripData: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [pickup_time: timestamp, dropoff_time: timestamp ... 4 more fields]\nroot\n |-- pickup_time: timestamp (nullable = true)\n |-- dropoff_time: timestamp (nullable = true)\n |-- pickup_latitude: double (nullable = true)\n |-- pickup_longitude: double (nullable = true)\n |-- dropoff_latitude: double (nullable = true)\n |-- dropoff_longitude: double (nullable = true)\n\n"}]},"apps":[],"jobName":"paragraph_1493506923076_1191235319","id":"20170426-152145_496769303","dateCreated":"2017-04-29T19:02:03-0400","dateStarted":"2017-04-30T08:51:19-0400","dateFinished":"2017-04-30T08:51:21-0400","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:4049"},{"text":"//form the feature vectors for pickup and dropoff data\nimport org.apache.spark.mllib.linalg.Vectors\nimport org.apache.spark.ml.feature.VectorAssembler\nval assembler_pickup_p = new VectorAssembler().setInputCols(Array(\"pickup_latitude\", \"pickup_longitude\")).setOutputCol(\"features\")\nval featureVector_pickup_p = assembler_pickup_p.transform(tripData).select(\"features\").cache()\nval assembler_dropoff_p = new VectorAssembler().setInputCols(Array(\"dropoff_latitude\", \"dropoff_longitude\")).setOutputCol(\"features\")\nval featureVector_dropoff_p = assembler_dropoff_p.transform(tripData).select(\"features\").cache()","user":"anonymous","dateUpdated":"2017-04-30T08:51:26-0400","config":{"enabled":true,"editorMode":"ace/mode/scala","results":{},"editorSetting":{"language":"scala"},"colWidth":12,"tableHide":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nimport org.apache.spark.mllib.linalg.Vectors\n\nimport org.apache.spark.ml.feature.VectorAssembler\n\nassembler_pickup_p: org.apache.spark.ml.feature.VectorAssembler = vecAssembler_61a63b21b516\n\nfeatureVector_pickup_p: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [features: vector]\n\nassembler_dropoff_p: org.apache.spark.ml.feature.VectorAssembler = vecAssembler_eddb3677d2e7\n\nfeatureVector_dropoff_p: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [features: vector]\n"}]},"apps":[],"jobName":"paragraph_1493506923080_1189696323","id":"20170426-153147_868935719","dateCreated":"2017-04-29T19:02:03-0400","dateStarted":"2017-04-30T08:51:26-0400","dateFinished":"2017-04-30T08:51:27-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4050"},{"text":"//train kMeansModel for pickup position\nimport org.apache.spark.ml.clustering.KMeans\nval kmeans = new KMeans().setK(150).setFeaturesCol(\"features\").setPredictionCol(\"prediction\").setMaxIter(10)\nval model_pickup = kmeans.fit(featureVector_pickup_p)","user":"anonymous","dateUpdated":"2017-04-30T08:51:30-0400","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1493556472210_951542522","id":"20170430-084752_361685489","dateCreated":"2017-04-30T08:47:52-0400","dateStarted":"2017-04-30T08:51:30-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4051","dateFinished":"2017-04-30T09:42:30-0400","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nimport org.apache.spark.ml.clustering.KMeans\n\nkmeans: org.apache.spark.ml.clustering.KMeans = kmeans_eb1bf435675b\n\nmodel_pickup: org.apache.spark.ml.clustering.KMeansModel = kmeans_eb1bf435675b\n"}]}},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1493557889237_-528215427","id":"20170430-091129_1979481396","dateCreated":"2017-04-30T09:11:29-0400","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:5311","text":"model_pickup.save(\"/user/yw2504/finalProject/kMeansModel\")\n//val sameModel = KMeansModel.load(sc, \"target/org/apache/spark/KMeansExample/KMeansModel\")","dateUpdated":"2017-04-30T09:45:57-0400","dateFinished":"2017-04-30T09:45:59-0400","dateStarted":"2017-04-30T09:45:57-0400","results":{"code":"SUCCESS","msg":[]}},{"text":"//load an filter the weather data, transform the data type\nval weather = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"model\", \"DROPMALFORMED\").load(\"/user/yw2504/finalProject/env.csv\")\nweather.createOrReplaceTempView(\"weather\")\nval date_weather_temp = spark.sql(\"select DATE, WEATHER, TEMPC from weather\").filter(\"TEMPC is not null\")\nval time = unix_timestamp($\"DATE\",\"yyyy-MM-dd HH\").cast(\"timestamp\")\nval time_weather_temp = date_weather_temp.withColumn(\"time\", time).drop(\"DATE\")\nval weatherData = time_weather_temp.withColumn(\"tempTmp\", time_weather_temp(\"TEMPC\").cast(DoubleType)).drop(\"TEMPC\").withColumnRenamed(\"tempTmp\", \"temp\").filter(\"temp is not null\")\nweatherData.createOrReplaceTempView(\"weatherData\")","user":"anonymous","dateUpdated":"2017-04-30T10:39:11-0400","config":{"enabled":true,"tableHide":true,"editorMode":"ace/mode/scala","results":{},"editorHide":false,"editorSetting":{"language":"scala"},"colWidth":12},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nweather: org.apache.spark.sql.DataFrame = [_c0: string, DATE: string ... 3 more fields]\n\ndate_weather_temp: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [DATE: string, WEATHER: string ... 1 more field]\n\ntime: org.apache.spark.sql.Column = CAST(unix_timestamp(DATE, yyyy-MM-dd HH) AS TIMESTAMP)\n\ntime_weather_temp: org.apache.spark.sql.DataFrame = [WEATHER: string, TEMPC: string ... 1 more field]\n\nweatherData: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [WEATHER: string, time: timestamp ... 1 more field]\n"}]},"apps":[],"jobName":"paragraph_1493506923082_1190465821","id":"20170426-152932_243847058","dateCreated":"2017-04-29T19:02:03-0400","dateStarted":"2017-04-30T10:39:11-0400","dateFinished":"2017-04-30T10:39:12-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4052"},{"text":"%sql\nselect hour(t.pickup_time) as hour, weather, count(*)\nfrom weatherData as w, tripData as t\nwhere year(w.time) = year(t.pickup_time) and month(w.time) = month(t.pickup_time) and day(w.time) = day(t.pickup_time) and hour(w.time) = hour(t.pickup_time)\ngroup by hour(t.pickup_time), weather\nhaving weather = \"snow\"","user":"anonymous","dateUpdated":"2017-04-29T20:29:03-0400","config":{"enabled":true,"tableHide":true,"editorMode":"ace/mode/sql","results":{"0":{"graph":{"mode":"multiBarChart","height":300,"optionOpen":true,"setting":{"multiBarChart":{}},"commonSetting":{},"keys":[{"name":"weather","index":1,"aggr":"sum"}],"groups":[{"name":"hour","index":0,"aggr":"sum"}],"values":[{"name":"count(1)","index":2,"aggr":"sum"}]},"helium":{}}},"editorSetting":{"language":"sql"},"colWidth":12},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"org.apache.spark.SparkException: Job 67 cancelled part of cancelled job group zeppelin-20170426-165611_1904028938\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435)\n\tat org.apache.spark.scheduler.DAGScheduler.handleJobCancellation(DAGScheduler.scala:1375)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleJobGroupCancelled$1.apply$mcVI$sp(DAGScheduler.scala:788)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleJobGroupCancelled$1.apply(DAGScheduler.scala:788)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleJobGroupCancelled$1.apply(DAGScheduler.scala:788)\n\tat scala.collection.mutable.HashSet.foreach(HashSet.scala:78)\n\tat org.apache.spark.scheduler.DAGScheduler.handleJobGroupCancelled(DAGScheduler.scala:788)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1625)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1918)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1931)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1944)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:333)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:38)\n\tat org.apache.spark.sql.Dataset$$anonfun$org$apache$spark$sql$Dataset$$execute$1$1.apply(Dataset.scala:2371)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:57)\n\tat org.apache.spark.sql.Dataset.withNewExecutionId(Dataset.scala:2765)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$execute$1(Dataset.scala:2370)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collect(Dataset.scala:2377)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2113)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2112)\n\tat org.apache.spark.sql.Dataset.withTypedCallback(Dataset.scala:2795)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2112)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2327)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat org.apache.zeppelin.spark.ZeppelinContext.showDF(ZeppelinContext.java:235)\n\tat org.apache.zeppelin.spark.SparkSqlInterpreter.interpret(SparkSqlInterpreter.java:130)\n\tat org.apache.zeppelin.interpreter.LazyOpenInterpreter.interpret(LazyOpenInterpreter.java:95)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreterServer$InterpretJob.jobRun(RemoteInterpreterServer.java:490)\n\tat org.apache.zeppelin.scheduler.Job.run(Job.java:175)\n\tat org.apache.zeppelin.scheduler.FIFOScheduler$1.run(FIFOScheduler.java:139)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:262)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:745)\n"}]},"apps":[],"jobName":"paragraph_1493506923085_1187772579","id":"20170426-165611_1904028938","dateCreated":"2017-04-29T19:02:03-0400","dateStarted":"2017-04-29T20:28:14-0400","dateFinished":"2017-04-29T20:29:01-0400","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:4054"},{"text":"//join trip data with weather data\nval DF_2 = spark.sql(\"select hour(t.pickup_time) as hour, w.weather, t.pickup_latitude, t.pickup_longitude, w.temp from weatherData as w, tripData as t where year(w.time) = year(t.pickup_time) and month(w.time) = month(t.pickup_time) and day(w.time) = day(t.pickup_time) and hour(w.time) = hour(t.pickup_time)\")\n                    ","user":"anonymous","dateUpdated":"2017-04-30T10:39:34-0400","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nDF_2: org.apache.spark.sql.DataFrame = [hour: int, weather: string ... 3 more fields]\n"}]},"apps":[],"jobName":"paragraph_1493509292693_335634428","id":"20170429-194132_1026958979","dateCreated":"2017-04-29T19:41:32-0400","dateStarted":"2017-04-30T10:39:34-0400","dateFinished":"2017-04-30T10:39:34-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4055"},{"text":"val assembler_trans = new VectorAssembler().setInputCols(Array(\"pickup_latitude\", \"pickup_longitude\")).setOutputCol(\"features\")\nval featureVector_trans = assembler_trans.transform(DF_2).drop(\"pickup_longitude\").drop(\"pickup_latitude\").cache()\nval DF_trans =  model_pickup.transform(featureVector_trans).withColumnRenamed(\"prediction\", \"kmPrediction\")drop(\"features\")\nDF_trans.printSchema","user":"anonymous","dateUpdated":"2017-04-30T10:52:28-0400","config":{"enabled":true,"tableHide":false,"editorMode":"ace/mode/scala","results":{},"editorSetting":{"language":"scala"},"colWidth":12},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1493506923086_1188926825","id":"20170426-170541_772916063","dateCreated":"2017-04-29T19:02:03-0400","dateStarted":"2017-04-30T10:52:28-0400","dateFinished":"2017-04-30T10:52:29-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4057","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nassembler_trans: org.apache.spark.ml.feature.VectorAssembler = vecAssembler_82aa60c4a247\n\nfeatureVector_trans: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [hour: int, weather: string ... 2 more fields]\n\nDF_trans: org.apache.spark.sql.DataFrame = [hour: int, weather: string ... 2 more fields]\nroot\n |-- hour: integer (nullable = true)\n |-- weather: string (nullable = true)\n |-- temp: double (nullable = true)\n |-- kmPrediction: integer (nullable = true)\n\n"}]}},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1493566669166_2066219959","id":"20170430-113749_1737597344","dateCreated":"2017-04-30T11:37:49-0400","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:7117","text":"DF_trans.createOrReplaceTempView(\"DF_trans\")\nval DF_trans_1 = spark.sql(\"select hour, weather, temp, kmPrediction, count(*) as num from DF_trans group by hour, weather, temp, kmPrediction\")","dateUpdated":"2017-04-30T11:39:38-0400","dateFinished":"2017-04-30T11:39:38-0400","dateStarted":"2017-04-30T11:39:38-0400","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nDF_trans_1: org.apache.spark.sql.DataFrame = [hour: int, weather: string ... 3 more fields]\n"}]}},{"text":"import org.apache.spark.ml.feature.StringIndexer\nval indexer = new StringIndexer().setInputCol(\"weather\").setOutputCol(\"weatherIndex\")\nval DF_trans_2 = indexer.fit(DF_trans_1).transform(DF_trans_1)","user":"anonymous","dateUpdated":"2017-04-30T11:39:53-0400","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nimport org.apache.spark.ml.feature.StringIndexer\n\nindexer: org.apache.spark.ml.feature.StringIndexer = strIdx_bd077c277c2a\n\nDF_trans_2: org.apache.spark.sql.DataFrame = [hour: int, weather: string ... 4 more fields]\n"}]},"apps":[],"jobName":"paragraph_1493511859257_-1012295332","id":"20170429-202419_331520046","dateCreated":"2017-04-29T20:24:19-0400","dateStarted":"2017-04-30T11:39:53-0400","dateFinished":"2017-04-30T11:44:56-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4059"},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1493561215396_722309617","id":"20170430-100655_270009137","dateCreated":"2017-04-30T10:06:55-0400","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:5747","text":"DF_trans_2.filter(\"temp is null\").show","dateUpdated":"2017-04-30T11:12:05-0400","dateFinished":"2017-04-30T11:12:10-0400","dateStarted":"2017-04-30T11:12:05-0400","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+----+-------+----+------------+------------+\n|hour|weather|temp|kmPrediction|weatherIndex|\n+----+-------+----+------------+------------+\n+----+-------+----+------------+------------+\n\n"}]}},{"text":"//legacy\nimport org.apache.spark.ml.feature.{OneHotEncoder, StringIndexer}\nval encoder = new OneHotEncoder()\n  .setInputCol(\"kMeansPrediction\")\n  .setOutputCol(\"kMeansPredictionVec\")\nval DF_trans_3_1 = encoder.transform(DF_trans_3)","user":"anonymous","dateUpdated":"2017-04-29T22:17:22-0400","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nimport org.apache.spark.ml.feature.{OneHotEncoder, StringIndexer}\n\nencoder: org.apache.spark.ml.feature.OneHotEncoder = oneHot_79a2167f191f\n\nDF_trans_3_1: org.apache.spark.sql.DataFrame = [hour: int, weather: string ... 4 more fields]\n"}]},"apps":[],"jobName":"paragraph_1493518569900_-1288798525","id":"20170429-221609_191306598","dateCreated":"2017-04-29T22:16:09-0400","dateStarted":"2017-04-29T22:17:22-0400","dateFinished":"2017-04-29T22:20:13-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4060"},{"text":"val assembler_RF = new VectorAssembler().setInputCols(Array(\"hour\", \"temp\", \"weatherIndex\", \"kmPrediction\")).setOutputCol(\"features\")\nval featureVector_RF = assembler_RF.transform(DF_trans_2).cache()\nfeatureVector_RF.printSchema","user":"anonymous","dateUpdated":"2017-04-30T11:53:38-0400","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nassembler_RF: org.apache.spark.ml.feature.VectorAssembler = vecAssembler_ea6930a7ed12\n\nfeatureVector_RF: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [hour: int, weather: string ... 5 more fields]\nroot\n |-- hour: integer (nullable = true)\n |-- weather: string (nullable = true)\n |-- temp: double (nullable = true)\n |-- kmPrediction: integer (nullable = true)\n |-- num: long (nullable = false)\n |-- weatherIndex: double (nullable = true)\n |-- features: vector (nullable = true)\n\n"}]},"apps":[],"jobName":"paragraph_1493515105144_1211784220","id":"20170429-211825_730954222","dateCreated":"2017-04-29T21:18:25-0400","dateStarted":"2017-04-30T11:53:38-0400","dateFinished":"2017-04-30T11:53:38-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4061"},{"text":"featureVector_RF.show","user":"anonymous","dateUpdated":"2017-04-30T10:26:35-0400","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+----+-------+----+------------+------------+--------------------+\n|hour|weather|temp|kmPrediction|weatherIndex|            features|\n+----+-------+----+------------+------------+--------------------+\n|  19| normal| 0.6|          85|         0.0| [19.0,0.6,0.0,85.0]|\n|  20| normal|-6.7|         118|         0.0|[20.0,-6.7,0.0,11...|\n|  20| normal|-6.7|         124|         0.0|[20.0,-6.7,0.0,12...|\n|  20| normal|-6.7|           6|         0.0| [20.0,-6.7,0.0,6.0]|\n|  20| normal|-6.7|         145|         0.0|[20.0,-6.7,0.0,14...|\n|  20| normal|-6.7|         103|         0.0|[20.0,-6.7,0.0,10...|\n|  20| normal|-6.7|          37|         0.0|[20.0,-6.7,0.0,37.0]|\n|  20| normal|-6.7|          29|         0.0|[20.0,-6.7,0.0,29.0]|\n|  20| normal|-6.7|          28|         0.0|[20.0,-6.7,0.0,28.0]|\n|  20| normal|-6.7|          27|         0.0|[20.0,-6.7,0.0,27.0]|\n|  20| normal|-6.7|          84|         0.0|[20.0,-6.7,0.0,84.0]|\n|  20| normal|-6.7|          85|         0.0|[20.0,-6.7,0.0,85.0]|\n|  20| normal|-6.7|         108|         0.0|[20.0,-6.7,0.0,10...|\n|  20| normal|-6.7|          11|         0.0|[20.0,-6.7,0.0,11.0]|\n|  20| normal|-6.7|          36|         0.0|[20.0,-6.7,0.0,36.0]|\n|  19| normal| 0.6|          64|         0.0| [19.0,0.6,0.0,64.0]|\n|  19| normal| 0.6|          46|         0.0| [19.0,0.6,0.0,46.0]|\n|  19| normal| 0.6|           5|         0.0|  [19.0,0.6,0.0,5.0]|\n|  19| normal| 0.6|          57|         0.0| [19.0,0.6,0.0,57.0]|\n|  19| normal| 0.6|         103|         0.0|[19.0,0.6,0.0,103.0]|\n+----+-------+----+------------+------------+--------------------+\nonly showing top 20 rows\n\n"}]},"apps":[],"jobName":"paragraph_1493522982824_-1501267527","id":"20170429-232942_34274521","dateCreated":"2017-04-29T23:29:42-0400","dateStarted":"2017-04-30T10:26:35-0400","dateFinished":"2017-04-30T10:35:57-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4063"},{"text":"featureVector_RF.show","user":"anonymous","dateUpdated":"2017-04-29T23:13:00-0400","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+----+-------+----------------+-----+------------+-------------------+--------------------+\n|hour|weather|kMeansPrediction|  num|weatherIndex|kMeansPredictionVec|            features|\n+----+-------+----------------+-----+------------+-------------------+--------------------+\n|   9| normal|             116|20750|         0.0|  (149,[116],[1.0])|(151,[1,118],[9.0...|\n|   9| normal|             149|13664|         0.0|        (149,[],[])|     (151,[1],[9.0])|\n|   9| normal|              46|26668|         0.0|   (149,[46],[1.0])|(151,[1,48],[9.0,...|\n|  11| normal|              14|  164|         0.0|   (149,[14],[1.0])|(151,[1,16],[11.0...|\n|  15| normal|              29|41334|         0.0|   (149,[29],[1.0])|(151,[1,31],[15.0...|\n|  17| normal|               8| 1502|         0.0|    (149,[8],[1.0])|(151,[1,10],[17.0...|\n|  22| normal|             111|30376|         0.0|  (149,[111],[1.0])|(151,[1,113],[22....|\n|   0| normal|              12|17309|         0.0|   (149,[12],[1.0])|    (151,[14],[1.0])|\n|   2| normal|              82| 9662|         0.0|   (149,[82],[1.0])|(151,[1,84],[2.0,...|\n|   4| normal|              88| 2952|         0.0|   (149,[88],[1.0])|(151,[1,90],[4.0,...|\n|   6| normal|              16|16344|         0.0|   (149,[16],[1.0])|(151,[1,18],[6.0,...|\n|   7| normal|              56|  188|         0.0|   (149,[56],[1.0])|(151,[1,58],[7.0,...|\n|   1|   snow|             139|  293|         3.0|  (149,[139],[1.0])|(151,[0,1,141],[3...|\n|   3|   snow|              11|  150|         3.0|   (149,[11],[1.0])|(151,[0,1,13],[3....|\n|   3|   snow|              83|  116|         3.0|   (149,[83],[1.0])|(151,[0,1,85],[3....|\n|   5|   snow|              33|   80|         3.0|   (149,[33],[1.0])|(151,[0,1,35],[3....|\n|   6|   snow|              84|   79|         3.0|   (149,[84],[1.0])|(151,[0,1,86],[3....|\n|   6|   snow|               7|   66|         3.0|    (149,[7],[1.0])|(151,[0,1,9],[3.0...|\n|   8|   snow|              44|  674|         3.0|   (149,[44],[1.0])|(151,[0,1,46],[3....|\n|  10|   snow|              72|  267|         3.0|   (149,[72],[1.0])|(151,[0,1,74],[3....|\n+----+-------+----------------+-----+------------+-------------------+--------------------+\nonly showing top 20 rows\n\n"}]},"apps":[],"jobName":"paragraph_1493521337388_-1830723667","id":"20170429-230217_456046112","dateCreated":"2017-04-29T23:02:17-0400","dateStarted":"2017-04-29T23:13:00-0400","dateFinished":"2017-04-29T23:15:24-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4064"},{"text":"val featureIndexer = new VectorIndexer().setInputCol(\"features\").setOutputCol(\"indexedFeatures\").setMaxCategories(30).fit(featureVector_RF)","user":"anonymous","dateUpdated":"2017-04-30T11:12:22-0400","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nfeatureIndexer: org.apache.spark.ml.feature.VectorIndexerModel = vecIdx_49bde558caab\n"}]},"apps":[],"jobName":"paragraph_1493526332739_2058575731","id":"20170430-002532_56114196","dateCreated":"2017-04-30T00:25:32-0400","dateStarted":"2017-04-30T11:12:22-0400","dateFinished":"2017-04-30T11:23:35-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4065"},{"text":"import org.apache.spark.ml.Pipeline\nimport org.apache.spark.ml.evaluation.RegressionEvaluator\nimport org.apache.spark.ml.feature.VectorIndexer\nimport org.apache.spark.ml.regression.{RandomForestRegressionModel, RandomForestRegressor}\n\nval featureIndexer = new VectorIndexer().setInputCol(\"features\").setOutputCol(\"indexedFeatures\").setMaxCategories(10).fit(featureVector_RF)\n\nval Array(trainingData, testData) = featureVector_RF.randomSplit(Array(0.7, 0.3))\n\nval rf = new RandomForestRegressor().setLabelCol(\"num\").setFeaturesCol(\"indexedFeatures\").setMaxBins(10).setNumTrees(50)\n\nval pipeline = new Pipeline().setStages(Array(featureIndexer, rf))\n","user":"anonymous","dateUpdated":"2017-04-30T12:46:22-0400","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nimport org.apache.spark.ml.Pipeline\n\nimport org.apache.spark.ml.evaluation.RegressionEvaluator\n\nimport org.apache.spark.ml.feature.VectorIndexer\n\nimport org.apache.spark.ml.regression.{RandomForestRegressionModel, RandomForestRegressor}\n\nfeatureIndexer: org.apache.spark.ml.feature.VectorIndexerModel = vecIdx_688dec119bb7\n\n\ntrainingData: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [hour: int, weather: string ... 5 more fields]\ntestData: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [hour: int, weather: string ... 5 more fields]\n\nrf: org.apache.spark.ml.regression.RandomForestRegressor = rfr_a4123fb6a948\n\npipeline: org.apache.spark.ml.Pipeline = pipeline_13eb094b9015\n"}]},"apps":[],"jobName":"paragraph_1493515342276_-320921293","id":"20170429-212222_1284583770","dateCreated":"2017-04-29T21:22:22-0400","dateStarted":"2017-04-30T12:46:22-0400","dateFinished":"2017-04-30T12:46:24-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4066"},{"text":"val model = pipeline.fit(trainingData)\nval predictions = model.transform(testData)\npredictions.select(\"prediction\", \"num\", \"features\").show(5)\n\nval evaluator = new RegressionEvaluator().setLabelCol(\"num\").setPredictionCol(\"prediction\").setMetricName(\"rmse\")\n\nval rmse = evaluator.evaluate(predictions)\nprintln(\"Root Mean Squared Error (RMSE) on test data = \" + rmse)\n\nval rfModel = model.stages(1).asInstanceOf[RandomForestRegressionModel]\nprintln(\"Learned regression forest model:\\n\" + rfModel.toDebugString)","user":"anonymous","dateUpdated":"2017-04-30T12:46:28-0400","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"msg":[{"data":"","type":"TEXT"}]},"apps":[],"jobName":"paragraph_1493517293668_-292493679","id":"20170429-215453_664743600","dateCreated":"2017-04-29T21:54:53-0400","dateStarted":"2017-04-30T12:46:28-0400","dateFinished":"2017-04-30T12:46:59-0400","status":"RUNNING","progressUpdateIntervalMs":500,"$$hashKey":"object:4068","errorMessage":""},{"text":"val testDF = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"model\", \"DROPMALFORMED\").load(\"/user/yw2504/finalProject/yellow/2016/*.csv\")\ntestDF.registerTempTable(\"trip\")\nval DF = spark.sql(\"select * from trip where VendorID not like '%end%'\")\nDF.registerTempTable(\"DF\")\nval df = sqlContext.sql(\"select pickup_latitude, pickup_longitude, dropoff_latitude, dropoff_longitude, tpep_pickup_datetime, tpep_dropoff_datetime from DF\")\nval pos_time = df.\n        withColumn(\"pickup_time\", pick_time).drop(\"tpep_pickup_datetime\").\n        withColumn(\"dropoff_time\", dropoff_time).drop(\"tpep_dropoff_datetime\").\n        withColumn(\"pickup_latitudeTmp\", df(\"pickup_latitude\").cast(DoubleType)).drop(\"pickup_latitude\").withColumnRenamed(\"pickup_latitudeTmp\", \"pickup_latitude\").\n\t\twithColumn(\"pickup_longitudeTmp\", df(\"pickup_longitude\").cast(DoubleType)).drop(\"pickup_longitude\").withColumnRenamed(\"pickup_longitudeTmp\", \"pickup_longitude\").\n\t\twithColumn(\"dropoff_latitudeTmp\", df(\"dropoff_latitude\").cast(DoubleType)).drop(\"dropoff_latitude\").withColumnRenamed(\"dropoff_latitudeTmp\", \"dropoff_latitude\").\n\t\twithColumn(\"dropoff_longitudeTmp\", df(\"dropoff_longitude\").cast(DoubleType)).drop(\"dropoff_longitude\").withColumnRenamed(\"dropoff_longitudeTmp\", \"dropoff_longitude\")\nval testData = pos_time.filter(pos_time(\"pickup_latitude\") < 40.915568 && pos_time(\"pickup_latitude\") > 40.495992).\n\t\tfilter(pos_time(\"pickup_longitude\") < -73.699215 && pos_time(\"pickup_longitude\") > -74.257159).\n\t\tfilter(pos_time(\"dropoff_latitude\") < 40.915568 && pos_time(\"dropoff_latitude\") > 40.495992).\n\t\tfilter(pos_time(\"dropoff_longitude\") < -73.699215 && pos_time(\"dropoff_longitude\") > -74.257159)","user":"anonymous","dateUpdated":"2017-04-29T19:36:51-0400","config":{"enabled":true,"editorMode":"ace/mode/scala","results":{},"editorSetting":{"language":"scala"},"colWidth":12},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\ntestDF: org.apache.spark.sql.DataFrame = [VendorID: string, tpep_pickup_datetime: string ... 17 more fields]\n\nwarning: there was one deprecation warning; re-run with -deprecation for details\n\nDF: org.apache.spark.sql.DataFrame = [VendorID: string, tpep_pickup_datetime: string ... 17 more fields]\n\nwarning: there was one deprecation warning; re-run with -deprecation for details\n\ndf: org.apache.spark.sql.DataFrame = [pickup_latitude: string, pickup_longitude: string ... 4 more fields]\n\npos_time: org.apache.spark.sql.DataFrame = [pickup_time: timestamp, dropoff_time: timestamp ... 4 more fields]\n\ntestData: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [pickup_time: timestamp, dropoff_time: timestamp ... 4 more fields]\n"}]},"apps":[],"jobName":"paragraph_1493506923087_1188542076","id":"20170426-193120_2048402765","dateCreated":"2017-04-29T19:02:03-0400","dateStarted":"2017-04-29T19:36:51-0400","dateFinished":"2017-04-29T19:36:52-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4069"},{"text":"val assembler_test = new VectorAssembler().setInputCols(Array(\"pickup_latitude\", \"pickup_longitude\")).setOutputCol(\"features\")\nval featureVector_test = assembler_test.transform(testData).select(\"features\").cache()","user":"anonymous","dateUpdated":"2017-04-29T19:36:55-0400","config":{"enabled":true,"editorMode":"ace/mode/scala","results":{},"editorSetting":{"language":"scala"},"colWidth":12},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nassembler_test: org.apache.spark.ml.feature.VectorAssembler = vecAssembler_e33fc2258e5d\n\nfeatureVector_test: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [features: vector]\n"}]},"apps":[],"jobName":"paragraph_1493506923088_1198930297","id":"20170428-234350_1479415678","dateCreated":"2017-04-29T19:02:03-0400","dateStarted":"2017-04-29T19:36:55-0400","dateFinished":"2017-04-29T19:36:55-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4070"},{"text":"//this is legacy, will not use \nval test = testData.rdd.map(s => (Vectors.dense(s.getDouble(2),s.getDouble(3))))","user":"anonymous","dateUpdated":"2017-04-29T19:36:56-0400","config":{"enabled":true,"editorMode":"ace/mode/scala","results":{},"editorSetting":{"language":"scala"},"colWidth":12},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\ntest: org.apache.spark.rdd.RDD[org.apache.spark.mllib.linalg.Vector] = MapPartitionsRDD[120] at map at <console>:43\n"}]},"apps":[],"jobName":"paragraph_1493506923089_1198545548","id":"20170428-235352_159619440","dateCreated":"2017-04-29T19:02:03-0400","dateStarted":"2017-04-29T19:36:57-0400","dateFinished":"2017-04-29T19:36:57-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4071"},{"text":"val predict_result =  model_pickup.transform(featureVector_pickup_p)\npredict_result.show(50, false)","user":"anonymous","dateUpdated":"2017-04-29T19:36:58-0400","config":{"enabled":true,"editorMode":"ace/mode/scala","results":{},"editorSetting":{"language":"scala"},"colWidth":12},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\npredict_result: org.apache.spark.sql.DataFrame = [features: vector, prediction: int]\n+---------------------------------------+----------+\n|features                               |prediction|\n+---------------------------------------+----------+\n|[40.73469543457031,-73.99037170410156] |27        |\n|[40.72991180419922,-73.98078155517578] |81        |\n|[40.6795654296875,-73.98455047607422]  |136       |\n|[40.718990325927734,-73.99346923828125]|131       |\n|[40.78133010864258,-73.96062469482422] |13        |\n|[40.74304962158203,-73.98011779785156] |45        |\n|[40.71998977661133,-73.99405670166016] |131       |\n|[40.74461364746094,-73.97942352294922] |11        |\n|[40.791046142578125,-73.94715118408203]|79        |\n|[40.72389602661133,-73.99834442138672] |97        |\n|[40.74491882324219,-74.00614929199219] |104       |\n|[40.7635383605957,-73.96932983398438]  |59        |\n|[40.72153854370117,-73.98902130126953] |68        |\n|[40.74224090576172,-74.00430297851562] |127       |\n|[40.71857833862305,-73.99199676513672] |131       |\n|[40.768951416015625,-73.98516082763672]|38        |\n|[40.79536056518555,-73.97309112548828] |111       |\n|[40.774696350097656,-73.98210144042969]|30        |\n|[40.71849822998047,-73.99484252929688] |131       |\n|[40.672115325927734,-73.95303344726562]|58        |\n|[40.72658920288086,-73.98916625976562] |22        |\n|[40.72017288208008,-73.99906921386719] |110       |\n|[40.74721908569336,-73.99713897705078] |98        |\n|[40.73667526245117,-73.9974136352539]  |145       |\n|[40.736961364746094,-73.99713134765625]|145       |\n|[40.71217346191406,-73.96391296386719] |52        |\n|[40.743900299072266,-73.99939727783203]|86        |\n|[40.77806854248047,-73.95440673828125] |135       |\n|[40.75455856323242,-73.99165344238281] |25        |\n|[40.744239807128906,-73.99559783935547]|98        |\n|[40.772010803222656,-73.99027252197266]|55        |\n|[40.75115203857422,-73.94010925292969] |7         |\n|[40.774879455566406,-73.9821548461914] |30        |\n|[40.742069244384766,-74.00806427001953]|127       |\n|[40.73063659667969,-74.00267791748047] |35        |\n|[40.773738861083984,-73.98165893554688]|30        |\n|[40.71915817260742,-73.98174285888672] |32        |\n|[40.77501678466797,-73.96305847167969] |144       |\n|[40.796199798583984,-73.96125793457031]|133       |\n|[40.7577018737793,-73.98223876953125]  |54        |\n|[40.636573791503906,-73.89412689208984]|123       |\n|[40.78913879394531,-73.94641876220703] |79        |\n|[40.74909973144531,-73.97567749023438] |103       |\n|[40.78461837768555,-73.94969177246094] |108       |\n|[40.716880798339844,-73.98184967041016]|68        |\n|[40.68856430053711,-73.96588134765625] |60        |\n|[40.76777267456055,-73.99586486816406] |12        |\n|[40.7451057434082,-73.97876739501953]  |11        |\n|[40.73356246948242,-73.97650146484375] |93        |\n|[40.78523635864258,-73.96937561035156] |34        |\n+---------------------------------------+----------+\nonly showing top 50 rows\n\n"}]},"apps":[],"jobName":"paragraph_1493506923090_1199699795","id":"20170428-234657_1379882509","dateCreated":"2017-04-29T19:02:03-0400","dateStarted":"2017-04-29T19:36:58-0400","dateFinished":"2017-04-29T19:36:59-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4072"},{"text":"import org.apache.spark.ml.linalg.DenseVector\nval vectorToColumn = udf{ (x:DenseVector, index: Int) => x(index) }","user":"anonymous","dateUpdated":"2017-04-29T19:37:05-0400","config":{"enabled":true,"editorMode":"ace/mode/scala","results":{},"editorSetting":{"language":"scala"},"colWidth":12},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nimport org.apache.spark.ml.linalg.DenseVector\n\nvectorToColumn: org.apache.spark.sql.expressions.UserDefinedFunction = UserDefinedFunction(<function2>,DoubleType,Some(List(org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7, IntegerType)))\n"}]},"apps":[],"jobName":"paragraph_1493506923091_1199315046","id":"20170429-002148_702733083","dateCreated":"2017-04-29T19:02:03-0400","dateStarted":"2017-04-29T19:37:05-0400","dateFinished":"2017-04-29T19:37:05-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4073"},{"text":"val predictResult = predict_result.withColumn(\"pickup_latitude\",vectorToColumn(col(\"features\"),lit(0))).withColumn(\"pickup_longitude\",vectorToColumn(col(\"features\"),lit(1))).drop(\"features\")\n","user":"anonymous","dateUpdated":"2017-04-29T19:37:08-0400","config":{"enabled":true,"editorMode":"ace/mode/scala","results":{},"editorSetting":{"language":"scala"},"colWidth":12},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\npredictResult: org.apache.spark.sql.DataFrame = [prediction: int, pickup_latitude: double ... 1 more field]\n"}]},"apps":[],"jobName":"paragraph_1493506923092_1197391301","id":"20170429-003221_312087156","dateCreated":"2017-04-29T19:02:03-0400","dateStarted":"2017-04-29T19:37:08-0400","dateFinished":"2017-04-29T19:37:08-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4074"},{"text":"predictResult.printSchema\npredictResult.show(50, false)\npredictResult.createOrReplaceTempView(\"predictResult\")\n","user":"anonymous","dateUpdated":"2017-04-29T19:37:10-0400","config":{"enabled":true,"editorMode":"ace/mode/scala","results":{},"editorSetting":{"language":"scala"},"colWidth":12},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"root\n |-- prediction: integer (nullable = true)\n |-- pickup_latitude: double (nullable = true)\n |-- pickup_longitude: double (nullable = true)\n\n+----------+------------------+------------------+\n|prediction|pickup_latitude   |pickup_longitude  |\n+----------+------------------+------------------+\n|27        |40.73469543457031 |-73.99037170410156|\n|81        |40.72991180419922 |-73.98078155517578|\n|136       |40.6795654296875  |-73.98455047607422|\n|131       |40.718990325927734|-73.99346923828125|\n|13        |40.78133010864258 |-73.96062469482422|\n|45        |40.74304962158203 |-73.98011779785156|\n|131       |40.71998977661133 |-73.99405670166016|\n|11        |40.74461364746094 |-73.97942352294922|\n|79        |40.791046142578125|-73.94715118408203|\n|97        |40.72389602661133 |-73.99834442138672|\n|104       |40.74491882324219 |-74.00614929199219|\n|59        |40.7635383605957  |-73.96932983398438|\n|68        |40.72153854370117 |-73.98902130126953|\n|127       |40.74224090576172 |-74.00430297851562|\n|131       |40.71857833862305 |-73.99199676513672|\n|38        |40.768951416015625|-73.98516082763672|\n|111       |40.79536056518555 |-73.97309112548828|\n|30        |40.774696350097656|-73.98210144042969|\n|131       |40.71849822998047 |-73.99484252929688|\n|58        |40.672115325927734|-73.95303344726562|\n|22        |40.72658920288086 |-73.98916625976562|\n|110       |40.72017288208008 |-73.99906921386719|\n|98        |40.74721908569336 |-73.99713897705078|\n|145       |40.73667526245117 |-73.9974136352539 |\n|145       |40.736961364746094|-73.99713134765625|\n|52        |40.71217346191406 |-73.96391296386719|\n|86        |40.743900299072266|-73.99939727783203|\n|135       |40.77806854248047 |-73.95440673828125|\n|25        |40.75455856323242 |-73.99165344238281|\n|98        |40.744239807128906|-73.99559783935547|\n|55        |40.772010803222656|-73.99027252197266|\n|7         |40.75115203857422 |-73.94010925292969|\n|30        |40.774879455566406|-73.9821548461914 |\n|127       |40.742069244384766|-74.00806427001953|\n|35        |40.73063659667969 |-74.00267791748047|\n|30        |40.773738861083984|-73.98165893554688|\n|32        |40.71915817260742 |-73.98174285888672|\n|144       |40.77501678466797 |-73.96305847167969|\n|133       |40.796199798583984|-73.96125793457031|\n|54        |40.7577018737793  |-73.98223876953125|\n|123       |40.636573791503906|-73.89412689208984|\n|79        |40.78913879394531 |-73.94641876220703|\n|103       |40.74909973144531 |-73.97567749023438|\n|108       |40.78461837768555 |-73.94969177246094|\n|68        |40.716880798339844|-73.98184967041016|\n|60        |40.68856430053711 |-73.96588134765625|\n|12        |40.76777267456055 |-73.99586486816406|\n|11        |40.7451057434082  |-73.97876739501953|\n|93        |40.73356246948242 |-73.97650146484375|\n|34        |40.78523635864258 |-73.96937561035156|\n+----------+------------------+------------------+\nonly showing top 50 rows\n\n"}]},"apps":[],"jobName":"paragraph_1493506923093_1197006552","id":"20170429-003332_552379085","dateCreated":"2017-04-29T19:02:03-0400","dateStarted":"2017-04-29T19:37:10-0400","dateFinished":"2017-04-29T19:37:10-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4075"},{"text":"%sql\nselect prediction, count(*)\nfrom predictResult\ngroup by prediction","user":"anonymous","dateUpdated":"2017-04-29T19:37:15-0400","config":{"enabled":true,"editorMode":"ace/mode/sql","results":{"0":{"graph":{"mode":"multiBarChart","height":300,"optionOpen":false},"helium":{}}},"editorSetting":{"language":"sql","editOnDblClick":false},"colWidth":12},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"prediction\tcount(1)\n148\t452876\n31\t116039\n85\t1474974\n137\t683491\n65\t836781\n53\t923537\n133\t248993\n78\t43836\n108\t530312\n34\t537137\n101\t556523\n115\t292170\n126\t646219\n81\t551486\n28\t16545\n76\t6770\n26\t616077\n27\t906674\n44\t1042969\n103\t893745\n12\t448268\n91\t602190\n22\t708386\n128\t821849\n122\t383420\n93\t117202\n111\t910086\n47\t75237\n140\t115712\n132\t3060\n146\t63655\n1\t294745\n52\t193256\n13\t666222\n86\t527369\n6\t897328\n16\t687328\n3\t910087\n142\t396747\n20\t24748\n40\t354\n139\t608527\n94\t367167\n57\t6122\n54\t1066152\n120\t45993\n96\t32728\n48\t74718\n5\t26916\n19\t1806\n92\t191324\n64\t274587\n117\t1524\n41\t854\n43\t439835\n15\t512539\n112\t21754\n37\t108282\n127\t970621\n61\t8712\n88\t599490\n107\t20654\n9\t1191512\n17\t592256\n72\t452917\n35\t759106\n114\t383178\n59\t765122\n4\t258020\n55\t452957\n100\t14935\n8\t56380\n39\t564132\n23\t706458\n49\t5765\n7\t137044\n130\t807315\n136\t134329\n84\t168635\n87\t926305\n51\t66818\n129\t675866\n69\t1895\n97\t586870\n63\t475909\n102\t426454\n10\t858064\n77\t6805\n50\t607155\n45\t605867\n38\t1251261\n82\t1153777\n80\t678180\n25\t1278947\n73\t1329564\n113\t583912\n24\t499046\n70\t17418\n62\t783375\n121\t399743\n125\t94563\n143\t219307\n95\t751962\n29\t754287\n21\t926552\n98\t603626\n32\t582990\n60\t52128\n90\t25687\n75\t1648\n141\t195243\n145\t734507\n109\t1163885\n56\t3781\n105\t788449\n58\t34679\n11\t597903\n33\t148238\n110\t489719\n83\t68586\n68\t701845\n71\t1063407\n106\t1097226\n116\t668698\n147\t52574\n14\t6529\n123\t6322\n135\t764544\n119\t718196\n42\t1039934\n79\t207282\n2\t1021371\n149\t352233\n131\t491137\n118\t7406\n124\t4364\n30\t1116493\n99\t567371\n66\t55575\n46\t746984\n67\t113596\n144\t744535\n0\t726081\n18\t21436\n74\t109739\n138\t19554\n104\t355782\n134\t349593\n36\t560571\n89\t57634\n"}]},"apps":[],"jobName":"paragraph_1493506923094_1198160799","id":"20170429-003407_648457721","dateCreated":"2017-04-29T19:02:03-0400","dateStarted":"2017-04-29T19:37:15-0400","dateFinished":"2017-04-29T19:39:38-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4076"},{"text":"val points = model_pickup.clusterCenters\n","user":"anonymous","dateUpdated":"2017-04-29T19:03:00-0400","config":{"enabled":true,"editorMode":"ace/mode/scala","results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":12},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"points: Array[org.apache.spark.ml.linalg.Vector] = Array([40.74311339290362,-73.99239429528352], [40.64559434628822,-73.77687172981146], [40.7814519440596,-73.98076452013524], [40.77389240186721,-73.87249913168786], [40.715802700362275,-73.9996013883682], [40.82362673576403,-73.91861487598126], [40.772979588986075,-73.95750660269763], [40.75109832592675,-73.93977526357402], [40.669878796536814,-73.98603888202794], [40.76418427580541,-73.97840291718276], [40.78852419464897,-73.97632627625455], [40.746060918120634,-73.9785624272451], [40.76474277126626,-73.99448279961031], [40.77768782246788,-73.96112255405188], [40.87741764676778,-73.89084810985632], [40.75856841474441,-74.00008370037217], [40.762143619686896,-73.9608292182964], [40.75001460080283,-74.00397275930293], [40.67167743390244,..."}]},"apps":[],"jobName":"paragraph_1493506923095_1197776050","id":"20170429-003826_1913039360","dateCreated":"2017-04-29T19:02:03-0400","dateStarted":"2017-04-29T19:30:34-0400","dateFinished":"2017-04-29T19:32:59-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4077"},{"text":"points(85)","user":"anonymous","dateUpdated":"2017-04-29T19:35:31-0400","config":{"enabled":true,"editorMode":"ace/mode/scala","results":{},"editorSetting":{"language":"scala"},"colWidth":12},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nres18: org.apache.spark.ml.linalg.Vector = [40.74955765050345,-73.99126941092594]\n"}]},"apps":[],"jobName":"paragraph_1493506923096_1195852306","id":"20170429-004451_606069522","dateCreated":"2017-04-29T19:02:03-0400","dateStarted":"2017-04-29T19:35:31-0400","dateFinished":"2017-04-29T19:35:31-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4078"},{"text":"import org.apache.spark.ml.feature.{OneHotEncoder, StringIndexer}\n\nval df = spark.createDataFrame(Seq(\n  (0, \"a\"),\n  (1, \"b\"),\n  (2, \"c\"),\n  (3, \"a\"),\n  (4, \"a\"),\n  (5, \"c\")\n)).toDF(\"id\", \"category\")\n\nval indexer = new StringIndexer()\n  .setInputCol(\"category\")\n  .setOutputCol(\"categoryIndex\")\n  .fit(df)\nval indexed = indexer.transform(df)\n\nval encoder = new OneHotEncoder()\n  .setInputCol(\"categoryIndex\")\n  .setOutputCol(\"categoryVec\")\n\nval encoded = encoder.transform(indexed)\nencoded.show()","user":"anonymous","dateUpdated":"2017-04-29T22:13:57-0400","config":{"enabled":true,"editorMode":"ace/mode/scala","results":{},"editorSetting":{"language":"scala"},"colWidth":12},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nimport org.apache.spark.ml.feature.{OneHotEncoder, StringIndexer}\n\ndf: org.apache.spark.sql.DataFrame = [id: int, category: string]\n\nindexer: org.apache.spark.ml.feature.StringIndexerModel = strIdx_6adff66eac9a\n\nindexed: org.apache.spark.sql.DataFrame = [id: int, category: string ... 1 more field]\n\nencoder: org.apache.spark.ml.feature.OneHotEncoder = oneHot_df50fd222e82\n\nencoded: org.apache.spark.sql.DataFrame = [id: int, category: string ... 2 more fields]\n+---+--------+-------------+-------------+\n| id|category|categoryIndex|  categoryVec|\n+---+--------+-------------+-------------+\n|  0|       a|          0.0|(2,[0],[1.0])|\n|  1|       b|          2.0|    (2,[],[])|\n|  2|       c|          1.0|(2,[1],[1.0])|\n|  3|       a|          0.0|(2,[0],[1.0])|\n|  4|       a|          0.0|(2,[0],[1.0])|\n|  5|       c|          1.0|(2,[1],[1.0])|\n+---+--------+-------------+-------------+\n\n"}]},"apps":[],"jobName":"paragraph_1493506923097_1195467557","id":"20170429-004609_951196153","dateCreated":"2017-04-29T19:02:03-0400","dateStarted":"2017-04-29T22:13:57-0400","dateFinished":"2017-04-29T22:13:58-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4079"},{"text":"encoded.printSchema","user":"anonymous","dateUpdated":"2017-04-29T22:15:26-0400","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"root\n |-- id: integer (nullable = false)\n |-- category: string (nullable = true)\n |-- categoryIndex: double (nullable = true)\n |-- categoryVec: vector (nullable = true)\n\n"}]},"apps":[],"jobName":"paragraph_1493518437536_-1599057736","id":"20170429-221357_476821746","dateCreated":"2017-04-29T22:13:57-0400","dateStarted":"2017-04-29T22:15:26-0400","dateFinished":"2017-04-29T22:15:26-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4080"},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1493518526288_-632078125","id":"20170429-221526_662729270","dateCreated":"2017-04-29T22:15:26-0400","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:4081"}],"name":"joinPositionTime","id":"2CEMUYDQA","angularObjects":{"2CFJKQVBN:shared_process":[],"2CF295UYG:shared_process":[],"2CDUTWP3P:shared_process":[],"2CD6ZRPDJ:shared_process":[],"2CG949ZHZ:shared_process":[],"2CG23YGEZ:shared_process":[],"2CEJ86HV3:shared_process":[],"2CEZMWG72:shared_process":[],"2CDY97F39:shared_process":[],"2CFXK5J4Y:shared_process":[],"2CFXDXWCE:shared_process":[],"2CEZV3CHG:shared_process":[],"2CDM4T1EH:shared_process":[],"2CEC5KMFB:shared_process":[],"2CFWFHNZR:shared_process":[],"2CFG6Y8G3:shared_process":[],"2CGYXR37V:shared_process":[],"2CFFWS5P3:shared_process":[],"2CFGNABPQ:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}